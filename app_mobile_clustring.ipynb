{"cells":[{"source":"import pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","metadata":{"executionCancelledAt":null,"executionTime":4132,"lastExecutedAt":1733430903681,"lastExecutedByKernel":"b8614d0b-376d-421a-843b-be6981a07f9a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize"},"id":"48172b7a-d771-435b-a6fe-c99134ac5eba","cell_type":"code","execution_count":1,"outputs":[]},{"source":"# Download necessary files from NLTK:\n# punkt -> Tokenization\n# stopwords -> Stop words removal\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":101,"type":"stream"}}},"id":"8a6577b0-9915-43c7-b1db-b0c106a71cca","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n"},{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":2}]},{"source":"# Load the reviews dataset and preview it\nreviews = pd.read_csv(\"reviews.csv\")\nreviews.head()","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":249,"type":"dataFrame"}}},"id":"7fbf3e3f-0526-4f53-908e-0bf9913f213d","cell_type":"code","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"content","type":"string"},{"name":"score","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"content":["I cannot open the app anymore","I have been begging for a refund from this app for over a month and nobody is replying me","Very costly for the premium version (approx Indian Rupees 910 per year). Better to download the premium version of this app from apkmos website and use it. Microsoft to do list app is far more better.","Used to keep me organized, but all the 2020 UPDATES have made a mess of things !!! Y cudn't u leave well enuf alone ??? Guess ur techies feel the need to keep making changes to justify continuing to collect their salary !!! ðŸ¤¤ðŸ¤¤ðŸ¤¤","Dan Birthday Oct 28"],"score":[1,1,1,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"                                             content  score\n0                      I cannot open the app anymore      1\n1  I have been begging for a refund from this app...      1\n2  Very costly for the premium version (approx In...      1\n3  Used to keep me organized, but all the 2020 UP...      1\n4                                Dan Birthday Oct 28      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I cannot open the app anymore</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I have been begging for a refund from this app...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Very costly for the premium version (approx In...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Used to keep me organized, but all the 2020 UP...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dan Birthday Oct 28</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":3}]},{"source":"# Your code starts here\n# Cells are free! Use as many as you need ;)\nprint(reviews['score'].unique())\nnegative_reviews = reviews.loc[reviews['score']< 3]\nprint(negative_reviews)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1733430904131,"lastExecutedByKernel":"b8614d0b-376d-421a-843b-be6981a07f9a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Your code starts here\n# Cells are free! Use as many as you need ;)\nprint(reviews['score'].unique())\nnegative_reviews = reviews.loc[reviews['score']< 3]\nprint(negative_reviews)","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"id":"3b2697f7-e85a-4a11-bfbb-59af07b89c75","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"[1 2 3 4 5]\n                                                 content  score\n0                          I cannot open the app anymore      1\n1      I have been begging for a refund from this app...      1\n2      Very costly for the premium version (approx In...      1\n3      Used to keep me organized, but all the 2020 UP...      1\n4                                    Dan Birthday Oct 28      1\n...                                                  ...    ...\n11940  I loved it until I realized that the very feat...      2\n11941  Gave it a test run and tried out the notificat...      2\n11942  Looks great but since installing, my device on...      2\n11943  This app looked good until I had to purchase i...      2\n11944                                           It's OK!      2\n\n[4850 rows x 2 columns]\n"}]},{"source":"def preprocess_text(text):\n    # Convert text to lowercase\n    text = text.lower()\n    # Remove non-alpha characters\n    text = re.sub(r'[^a-z\\s]', '', text)\n    # Tokenize the text\n    tokens = nltk.word_tokenize(text)\n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    tokens = [word for word in tokens if word not in stop_words]\n    return tokens\n\n# Apply preprocessing to negative reviews\nnegative_reviews['preprocessed_content'] = negative_reviews['content'].apply(preprocess_text)\n\n\n# Save to a new DataFrame\npreprocessed_reviews = negative_reviews[['preprocessed_content', 'score']]\n\n# Display the preprocessed DataFrame\nprint(preprocessed_reviews)","metadata":{"executionCancelledAt":null,"executionTime":1338,"lastExecutedAt":1733430905469,"lastExecutedByKernel":"b8614d0b-376d-421a-843b-be6981a07f9a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def preprocess_text(text):\n    # Convert text to lowercase\n    text = text.lower()\n    # Remove non-alpha characters\n    text = re.sub(r'[^a-z\\s]', '', text)\n    # Tokenize the text\n    tokens = nltk.word_tokenize(text)\n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    tokens = [word for word in tokens if word not in stop_words]\n    return tokens\n\n# Apply preprocessing to negative reviews\nnegative_reviews['preprocessed_content'] = negative_reviews['content'].apply(preprocess_text)\n\n\n# Save to a new DataFrame\npreprocessed_reviews = negative_reviews[['preprocessed_content', 'score']]\n\n# Display the preprocessed DataFrame\nprint(preprocessed_reviews)","outputsMetadata":{"0":{"height":311,"type":"stream"}}},"cell_type":"code","id":"b8dae1f6-7540-4871-ac7d-c811013bdbff","outputs":[{"output_type":"stream","name":"stdout","text":"                                    preprocessed_content  score\n0                                   [open, app, anymore]      1\n1        [begging, refund, app, month, nobody, replying]      1\n2      [costly, premium, version, approx, indian, rup...      1\n3      [used, keep, organized, updates, made, mess, t...      1\n4                                   [dan, birthday, oct]      1\n...                                                  ...    ...\n11940  [loved, realized, feature, got, download, firs...      2\n11941  [gave, test, run, tried, notifications, didnt,...      2\n11942  [looks, great, since, installing, device, last...      2\n11943  [app, looked, good, purchase, get, week, view,...      2\n11944                                               [ok]      2\n\n[4850 rows x 2 columns]\n"}],"execution_count":5},{"source":"# Convert lists of tokens to strings because TfidfVectorizer want plain strings \npreprocessed_reviews[\"preprocessed_content\"] = preprocessed_reviews[\"preprocessed_content\"].apply(lambda x: ' '.join(x))\n\n# Vectorize the cleaned reviews using TF-IDF\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"preprocessed_content\"])\n\n# Step 3: Apply K-means clustering to tfidf_matrix\n\n# Apply K-means clustering (store the model as clust_kmeans)\nclust_kmeans = KMeans(n_clusters=5, random_state=500)\npred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n\n# Store the predicted labels in a list variable called categories\ncategories = pred_labels.tolist()\npreprocessed_reviews[\"category\"] = categories\n\n# Step 4: For each unique cluster label, find the most frequent term\n\n# Get the feature names (terms) from the vectorizer\nterms = vectorizer.get_feature_names_out()\n\n# List to save the top term for each cluster\ntopic_terms_list = []\n\n# Iterate over each cluster\nfor cluster in range(clust_kmeans.n_clusters):\n    # Get indices of reviews in the current cluster\n    cluster_indices = np.where(np.array(categories) == cluster)[0]  # Simplified using NumPy\n    \n    # Compute the sum of tf-idf scores for terms in the cluster\n    cluster_term_freq = tfidf_matrix[cluster_indices].sum(axis=0).A1  # Convert to 1D array\n    \n    # Append the top term for the current cluster\n    top_term_index = cluster_term_freq.argmax()\n    topic_terms_list.append(\n        {\n            \"category\": cluster,\n            \"term\": terms[top_term_index],\n            \"frequency\": cluster_term_freq[top_term_index],\n        }\n    )\n\n","metadata":{"executionCancelledAt":null,"executionTime":585,"lastExecutedAt":1733430906054,"lastExecutedByKernel":"b8614d0b-376d-421a-843b-be6981a07f9a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Convert lists of tokens to strings because TfidfVectorizer want plain strings \npreprocessed_reviews[\"preprocessed_content\"] = preprocessed_reviews[\"preprocessed_content\"].apply(lambda x: ' '.join(x))\n\n# Vectorize the cleaned reviews using TF-IDF\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(preprocessed_reviews[\"preprocessed_content\"])\n\n# Step 3: Apply K-means clustering to tfidf_matrix\n\n# Apply K-means clustering (store the model as clust_kmeans)\nclust_kmeans = KMeans(n_clusters=5, random_state=500)\npred_labels = clust_kmeans.fit_predict(tfidf_matrix)\n\n# Store the predicted labels in a list variable called categories\ncategories = pred_labels.tolist()\npreprocessed_reviews[\"category\"] = categories\n\n# Step 4: For each unique cluster label, find the most frequent term\n\n# Get the feature names (terms) from the vectorizer\nterms = vectorizer.get_feature_names_out()\n\n# List to save the top term for each cluster\ntopic_terms_list = []\n\n# Iterate over each cluster\nfor cluster in range(clust_kmeans.n_clusters):\n    # Get indices of reviews in the current cluster\n    cluster_indices = np.where(np.array(categories) == cluster)[0]  # Simplified using NumPy\n    \n    # Compute the sum of tf-idf scores for terms in the cluster\n    cluster_term_freq = tfidf_matrix[cluster_indices].sum(axis=0).A1  # Convert to 1D array\n    \n    # Append the top term for the current cluster\n    top_term_index = cluster_term_freq.argmax()\n    topic_terms_list.append(\n        {\n            \"category\": cluster,\n            \"term\": terms[top_term_index],\n            \"frequency\": cluster_term_freq[top_term_index],\n        }\n    )\n\n","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"72e0d3c5-5191-4cd1-aefd-f5b73773d67e","outputs":[],"execution_count":6},{"source":"# Pandas DataFrame to store results from this step\ntopic_terms = pd.DataFrame(topic_terms_list)\n\n# Output the final result\nprint(topic_terms)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1733430906111,"lastExecutedByKernel":"b8614d0b-376d-421a-843b-be6981a07f9a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Pandas DataFrame to store results from this step\ntopic_terms = pd.DataFrame(topic_terms_list)\n\n# Output the final result\nprint(topic_terms)","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"a5fbb76e-64f5-467a-b443-fd8c05561543","outputs":[{"output_type":"stream","name":"stdout","text":"   category     term   frequency\n0         0     work   57.690096\n1         1     good   37.197798\n2         2  version   66.128081\n3         3      app  183.821473\n4         4     time   60.083806\n"}],"execution_count":7}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}